{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transform GTSDB Dataset annotations to COCO Format"]},{"cell_type":"markdown","metadata":{},"source":["To use Detectron2 to train the object detection model, the dataset should be in COCO format. Given that GTSDB dataset is not in a standard format, I will start the data preparation by data transformation to COCO format (inspired from [here](http://https://gist.github.com/zhaoweizhong/053ce08beb9047b710b3616f75130c31))"]},{"cell_type":"markdown","metadata":{},"source":["## download data from GTSDB website"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! wget https://sid.erda.dk/public/archives/ff17dc924eba88d5d01a807357d6614c/FullIJCNN2013.zip"]},{"cell_type":"markdown","metadata":{},"source":["## convert annotations to COCO format"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["we extract categories information from dataset description file"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["label_dict = {\n","    0: \"20km/h\",\n","    1: \"30km/h\",\n","    2: \"50km/h\",\n","    3: \"60km/h\",\n","    4: \"70km/h\",\n","    5: \"80km/h\",\n","    6: \"End of 80km/h\",\n","    7: \"100km/h\",\n","    8: \"120km/h\",\n","    9: \"No overtaking\",\n","    10: \"No overtaking (trucks)\",\n","    11: \"Priority intersection\",\n","    12: \"Priority road\",\n","    13: \"Give way\",\n","    14: \"Stop\",\n","    15: \"No traffic\",\n","    16: \"No trucks\",\n","    17: \"No entry\",\n","    18: \"Danger\",\n","    19: \"Bend left\",\n","    20: \"Bend right\",\n","    21: \"Bend\",\n","    22: \"Uneven road\",\n","    23: \"Slippery road\",\n","    24: \"Road narrows\",\n","    25: \"Construction\",\n","    26: \"Traffic signal\",\n","    27: \"Pedestrian crossing\",\n","    28: \"School crossing\",\n","    29: \"Cycles crossing\",\n","    30: \"Snow\",\n","    31: \"Animals\",\n","    32: \"End of restriction\",\n","    33: \"Go right\",\n","    34: \"Go left\",\n","    35: \"Go straight\",\n","    36: \"Go right or straight\",\n","    37: \"Go left or straight\",\n","    38: \"Keep right\",\n","    39: \"Keep left\",\n","    40: \"Roundabout\",\n","    41: \"End of overtaking restriction\",\n","    42: \"End of overtaking restriction (trucks)\"\n","}"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T16:59:57.367832Z","iopub.status.busy":"2023-11-30T16:59:57.367395Z","iopub.status.idle":"2023-11-30T16:59:57.385452Z","shell.execute_reply":"2023-11-30T16:59:57.384417Z","shell.execute_reply.started":"2023-11-30T16:59:57.367800Z"},"trusted":true},"outputs":[],"source":["import json\n","import argparse\n","import copy\n","import tqdm\n","\n","def load_txt(file_name):\n","    file = open(file_name, 'r')\n","    data = []\n","    for line in file.readlines():\n","        data.append(line.replace('\\n', ''))\n","    return data"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:01:23.187208Z","iopub.status.busy":"2023-11-30T17:01:23.186791Z","iopub.status.idle":"2023-11-30T17:01:23.206144Z","shell.execute_reply":"2023-11-30T17:01:23.205174Z","shell.execute_reply.started":"2023-11-30T17:01:23.187171Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['00000.ppm;774;411;815;446;11',\n"," '00001.ppm;983;388;1024;432;40',\n"," '00001.ppm;386;494;442;552;38',\n"," '00001.ppm;973;335;1031;390;13',\n"," '00002.ppm;892;476;1006;592;39']"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["file_name = \"dataset/FullIJCNN2013/gt.txt\"\n","data = load_txt(file_name)\n","data[:5]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["1213"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["len(img_id_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PIL import Image\n","\n","def convert_ppm_to_jpg(ppm_path, jpg_path):\n","    img = Image.open(ppm_path)\n","    img.save(jpg_path, 'JPEG')"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["import os\n","from PIL import Image\n","\n","def convert_ppm_to_jpg(source_dir, dest_dir):\n","    for filename in os.listdir(source_dir):\n","        if filename.endswith('.ppm'):\n","            img = Image.open(os.path.join(source_dir, filename))\n","            jpg_filename = os.path.splitext(filename)[0] + '.jpg'\n","            img.save(os.path.join(dest_dir, jpg_filename), 'JPEG')\n","convert_ppm_to_jpg('dataset/FullIJCNN2013', 'dataset/img_jpg')"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 00000.jpg 774 411 815 446 11\n"]}],"source":["annotation = data[0]\n","img_id = int(annotation.split(';')[0][:5])\n","img_name = annotation.split(';')[0][:5] + '.jpg'\n","xmin = int(annotation.split(';')[1])\n","ymin = int(annotation.split(';')[2])\n","xmax = int(annotation.split(';')[3])\n","ymax = int(annotation.split(';')[4])\n","class_id = int(annotation.split(';')[5])\n","print(img_id, img_name, xmin, ymin, xmax, ymax, class_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def parse(data):\n","    # File Format\n","    result_train = {\n","        \"licenses\": [\n","            {\n","                \"url\": \"https://creativecommons.org/licenses/by-nc-sa/4.0/\",\n","                \"id\": 1,\n","                \"name\": \"Attribution-NonCommercial-ShareAlike 4.0 International License (CC BY-NC-SA 4.0)\"\n","            }\n","        ],\n","        \"images\": [],\n","        \"annotations\": [],\n","        \"categories\": []\n","    }\n","\n","    for i in range(0, 43):\n","        result_train['categories'].append({\n","            \"id\": i,\n","            \"name\": label_dict[i],\n","        })\n","\n","    result_test = copy.deepcopy(result_train)\n","\n","    # Images and Annotations\n","    count = 900\n","    count_train = int(count * 0.7)\n","    anno_id = 0\n","    for annotation in tqdm.tqdm(data):\n","        img_id = int(annotation.split(';')[0][:5])\n","        img_name = annotation.split(';')[0][:5] + '.jpg'\n","        xmin = int(annotation.split(';')[1])\n","        ymin = int(annotation.split(';')[2])\n","        xmax = int(annotation.split(';')[3])\n","        ymax = int(annotation.split(';')[4])\n","        class_id = int(annotation.split(';')[5])\n","        if img_id < count_train:\n","            # if not bool([True for img in result_train['images'] if img['id'] == img_id]):\n","            result_train['images'].append({\n","                \"license\": 1,\n","                \"file_name\": img_name,\n","                \"height\": 800,\n","                \"width\": 1360,\n","                \"id\": img_id\n","            })\n","            result_train['annotations'].append({\n","                \"segmentation\": [[]],\n","                \"area\": (xmax - xmin) * (ymax - ymin),\n","                \"iscrowd\": 0,\n","                \"image_id\": img_id,\n","                \"bbox\": [\n","                    xmin,\n","                    ymin,\n","                    xmax - xmin,\n","                    ymax - ymin\n","                ],\n","                \"category_id\": class_id,\n","                \"id\": anno_id\n","            })\n","        else:\n","            print(result_train['images'][-1])\n","            print(img_id)\n","            break\n","            if not bool([True for img in result_test['images'] if img['id'] == img_id]):\n","                result_test['images'].append({\n","                    \"license\": 1,\n","                    \"file_name\": img_name,\n","                    \"height\": 800,\n","                    \"width\": 1360,\n","                    \"id\": img_id\n","                })\n","            result_test['annotations'].append({\n","                \"segmentation\": [[]],\n","                \"area\": (xmax - xmin) * (ymax - ymin),\n","                \"iscrowd\": 0,\n","                \"image_id\": img_id,\n","                \"bbox\": [\n","                    xmin,\n","                    ymin,\n","                    xmax - xmin,\n","                    ymax - ymin\n","                ],\n","                \"category_id\": class_id,\n","                \"id\": anno_id\n","            })\n","        anno_id = anno_id + 1\n","    \n","    print('Train Images: ' + str(len(result_train['images'])))\n","    print('Test Images: ' + str(len(result_test['images'])))\n","    print('Train Annotations: ' + str(len(result_train['annotations'])))\n","    print('Test Annotations: ' + str(len(result_test['annotations'])))\n","\n","    with open('train.json', \"w\") as f:\n","        json.dump(result_train, f)\n","\n","    with open('test.json', \"w\") as f:\n","        json.dump(result_test, f)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:23:23.760602Z","iopub.status.busy":"2023-11-30T17:23:23.759860Z","iopub.status.idle":"2023-11-30T17:23:23.767884Z","shell.execute_reply":"2023-11-30T17:23:23.766868Z","shell.execute_reply.started":"2023-11-30T17:23:23.760560Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['00000.ppm;774;411;815;446;11',\n"," '00001.ppm;983;388;1024;432;40',\n"," '00001.ppm;386;494;442;552;38',\n"," '00001.ppm;973;335;1031;390;13',\n"," '00002.ppm;892;476;1006;592;39']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data[:5]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["1213"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(data)"]},{"cell_type":"markdown","metadata":{},"source":["Each row contains the file name, bounding box coordinates and label index."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:24:30.574507Z","iopub.status.busy":"2023-11-30T17:24:30.573356Z","iopub.status.idle":"2023-11-30T17:24:30.648910Z","shell.execute_reply":"2023-11-30T17:24:30.647616Z","shell.execute_reply.started":"2023-11-30T17:24:30.574466Z"},"trusted":true},"outputs":[],"source":["parse(data)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:29:42.144707Z","iopub.status.busy":"2023-11-30T17:29:42.144341Z","iopub.status.idle":"2023-11-30T17:29:42.153151Z","shell.execute_reply":"2023-11-30T17:29:42.152062Z","shell.execute_reply.started":"2023-11-30T17:29:42.144680Z"},"trusted":true},"outputs":[],"source":["# have a look at json file\n","import json\n","with open(\"train.json\", \"rb\") as f:\n","    train_data = json.load(f)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:29:48.478232Z","iopub.status.busy":"2023-11-30T17:29:48.477851Z","iopub.status.idle":"2023-11-30T17:29:48.484899Z","shell.execute_reply":"2023-11-30T17:29:48.483765Z","shell.execute_reply.started":"2023-11-30T17:29:48.478198Z"},"trusted":true},"outputs":[{"data":{"text/plain":["dict_keys(['licenses', 'images', 'annotations', 'categories'])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_data.keys()"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T17:30:05.608746Z","iopub.status.busy":"2023-11-30T17:30:05.607369Z","iopub.status.idle":"2023-11-30T17:30:05.620458Z","shell.execute_reply":"2023-11-30T17:30:05.619234Z","shell.execute_reply.started":"2023-11-30T17:30:05.608670Z"},"trusted":true},"outputs":[{"data":{"text/plain":["530"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data['images'])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["[{'license': 1,\n","  'file_name': '00628.jpg',\n","  'height': 800,\n","  'width': 1360,\n","  'id': 628}]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_data['images'][-1:]"]},{"cell_type":"markdown","metadata":{},"source":["Since we focus on speed limit detection, we select only the traffic signs related to speed limit as training data. In GTSDB,  they are correspondings to following label indexes: [0, 1, 2, 3, 4, 5, 7, 8]. By refering to dataset description in ReadMe.txt file, we build the following label mapping dict for the categories that we are interested in:"]},{"cell_type":"markdown","metadata":{},"source":["speed_limit_dict = {\n","    0: \"20km/h\",\n","    1: \"30km/h\",\n","    2: \"50km/h\",\n","    3: \"60km/h\",\n","    4: \"70km/h\",\n","    5: \"80km/h\",\n","    6: \"End of 80km/h\",\n","    7: \"100km/h\",\n","    8: \"120km/h\"\n","}"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":985376,"sourceId":1664166,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
